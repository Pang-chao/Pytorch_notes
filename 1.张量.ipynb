{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch基本数据抽象为张量，可以这样创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[1.4411e+12, 3.0669e-41],\n         [1.3756e+12, 3.0669e-41],\n         [8.9683e-44, 0.0000e+00]]),\n tensor([[0.5275, 0.9302],\n         [0.6251, 0.0768],\n         [0.8794, 0.5663]]),\n tensor([[1., 1.],\n         [1., 1.],\n         [1., 1.]]),\n tensor([[0., 0.],\n         [0., 0.],\n         [0., 0.]]))"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "uninitialized = torch.Tensor(3,2)\n",
    "rand_initialized = torch.rand(3,2)\n",
    "matrix_ones = torch.ones(3,2)\n",
    "matrix_zeros = torch.zeros(3,2)\n",
    "\n",
    "uninitialized, rand_initialized, matrix_ones, matrix_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "调用shape属性，或通过size可以获取张量的形状\n",
    "\n",
    "张量也可进行切片操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "size = rand_initialized.size()\n",
    "shape = rand_initialized.shape\n",
    "print(size == shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "shape对象继承自元组，不可变"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "张量对象满足python数值运算，运算符与普通运算符一样"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 1.],\n        [1., 1.],\n        [1., 1.]])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(3,2)\n",
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[3., 3.],\n        [3., 3.],\n        [3., 3.]])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones(3,2) + 2\n",
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.],\n        [1.]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.ones(2,1)\n",
    "z"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[6.],\n        [6.],\n        [6.]])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x * y @ z"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "乘法运算符执行元素乘法，@运算符为矩阵乘法，也可用函数mm或matmul完成。\n",
    "存在多种用于张量操作的选项，python运算符，in-place的pytorch函数与out-place的pytorch函数。\n",
    "add不改变被加数，add_会改变（即in-place）。\n",
    "具有in-place特性的操作会在最后加一个下划线。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[4., 4.],\n        [4., 4.],\n        [4., 4.]])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.add(y)\n",
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[7., 7.],\n        [7., 7.],\n        [7., 7.]])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.add_(y)\n",
    "z"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.3371, 0.9340, 1.1710, 0.3482],\n        [2.1146, 1.3626, 1.8980, 0.5046]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2,3)\n",
    "y = torch.rand(3,4)\n",
    "x.matmul(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "index类似于标准的python列表，可以使用index_select()进行索引"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
      "tensor([2, 3])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([[0, 1],\n",
      "        [3, 4],\n",
      "        [6, 7]])\n",
      "tensor([[[0, 1, 2],\n",
      "         [3, 4, 5],\n",
      "         [6, 7, 8]]])\n",
      "tensor([[[0, 1, 2],\n",
      "         [3, 4, 5],\n",
      "         [6, 7, 8]]])\n"
     ]
    }
   ],
   "source": [
    "# 创建1D张量\n",
    "a = torch.arange(0, 9)\n",
    "print(a)\n",
    "# 获取1D张量的第1个维度且索引号为2和3的张量子集\n",
    "print(torch.index_select(a, dim = 0, index = torch.tensor([2, 3])))\n",
    "\n",
    "# 创建2D张量\n",
    "b = torch.arange(0, 9).view([3, 3])\n",
    "print(b)\n",
    "# 获取2D张量的第2个维度且索引号为0和1的张量子集(第一列和第二列)\n",
    "print(torch.index_select(b, dim = 1, index = torch.tensor([0, 1])))\n",
    "\n",
    "# 创建3D张量\n",
    "c = torch.arange(0, 9).view([1, 3, 3])\n",
    "print(c)\n",
    "# 获取3D张量的第1个维度且索引号为0的张量子集\n",
    "print(torch.index_select(c, dim = 0, index = torch.tensor([0])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "连接是另一个重要操作，cat可以对只有一个维度大小不同的两个张量进行连接。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0.4752, 0.1972, 0.6006, 0.7660],\n         [0.2700, 0.5702, 0.9233, 0.2681],\n         [0.9825, 0.6635, 0.2156, 0.8382],\n         [0.1175, 0.3444, 0.6000, 0.6853],\n         [0.8817, 0.1497, 0.2189, 0.3294],\n         [0.6550, 0.9965, 0.6749, 0.5816],\n         [0.4026, 0.9828, 0.5191, 0.8205]],\n\n        [[0.3660, 0.1144, 0.9643, 0.7446],\n         [0.0202, 0.1803, 0.6829, 0.7139],\n         [0.7678, 0.4584, 0.5009, 0.3447],\n         [0.2344, 0.8605, 0.4351, 0.6416],\n         [0.8061, 0.5186, 0.2129, 0.7069],\n         [0.9755, 0.4493, 0.8917, 0.4941],\n         [0.9799, 0.5296, 0.8898, 0.1977]],\n\n        [[0.2407, 0.9414, 0.5146, 0.3085],\n         [0.6784, 0.4069, 0.8438, 0.4519],\n         [0.6926, 0.8479, 0.9288, 0.3499],\n         [0.1628, 0.4967, 0.1928, 0.0581],\n         [0.2368, 0.2999, 0.4323, 0.8609],\n         [0.9316, 0.6592, 0.9398, 0.5932],\n         [0.3054, 0.6573, 0.4194, 0.1188]]])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(3,2,4)\n",
    "b = torch.rand(3,5,4)\n",
    "#将a与b在第一个维度上拼接\n",
    "c = torch.cat((a,b), 1)\n",
    "c"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "如果要向张量中添加新维度，使用stack。\n",
    "对于torch.stack来说，会先将原始数据维度扩展一维，\n",
    "然后再按照维度进行拼接，具体拼接操作同torch.cat类似。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[[1., 1., 1., 1.],\n           [2., 2., 2., 2.]]]],\n\n\n\n        [[[[3., 3., 3., 3.],\n           [4., 4., 4., 4.]]]]])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a0=torch.Tensor([[[[1,1,1,1],[2,2,2,2]]]])\n",
    "a1=torch.Tensor([[[[3,3,3,3],[4,4,4,4]]]])\n",
    "torch.stack((a0,a1),dim=0).type(torch.FloatTensor)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "split与chunk用于拆分张量，split接受每个输出张量的期望大小。\n",
    "对tensor在某一dim维度下，根据指定的大小split_size=int，或者list(int)来分割数据，返回张量列表。\n",
    "\n",
    "注意两个细节：1、当split_size为一个int数时，若不能整除int，剩余的数据直接作为一块。\n",
    "2、当split_size为一个列表时，所有数字的和等于要分割的维度大小。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "torch.Size([4, 3, 8])\n",
      "torch.Size([4, 3, 8])\n",
      "torch.Size([4, 3, 8])\n",
      "torch.Size([4, 1, 8])\n",
      "<class 'tuple'>\n",
      "torch.Size([4, 3, 8])\n",
      "torch.Size([4, 3, 8])\n",
      "torch.Size([4, 3, 8])\n",
      "torch.Size([4, 1, 8])\n"
     ]
    }
   ],
   "source": [
    "#细节1\n",
    "input1 = torch.randn(4,10,8)\n",
    "output1 = torch.split(input1, 3, dim=1) #3+3+3+1=10,不够的单独作为一块\n",
    "print(type(output1))\n",
    "for chunk in output1:\n",
    "    print(chunk.size())\n",
    "\n",
    "#细节2\n",
    "input2 = torch.randn(4,10,8)\n",
    "split_list = [3, 3, 3, 1]\n",
    "output2 = torch.split(input2, split_list, dim=1) #3+3+3+1=10\n",
    "print(type(output2))\n",
    "for chunk in output2:\n",
    "    print(chunk.size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "chunk方法可以对张量分块，返回一个张量列表。\n",
    "同上，若不能整除int，剩余的数据直接作为一块。\n",
    "\n",
    "区别：\n",
    "（1）chunks只能是int型，而split_size_or_section可以是list。\n",
    "\n",
    "（2）chunks在时，不满足该维度下的整除关系，会将块按照维度切分成1的结构。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "torch.Size([4, 1, 8])\n",
      "torch.Size([4, 1, 8])\n",
      "torch.Size([4, 1, 8])\n",
      "torch.Size([4, 1, 8])\n",
      "torch.Size([4, 1, 8])\n",
      "torch.Size([4, 1, 8])\n",
      "torch.Size([4, 1, 8])\n",
      "torch.Size([4, 1, 8])\n",
      "torch.Size([4, 1, 8])\n",
      "torch.Size([4, 1, 8])\n",
      "tensor([[[-8.7442e-01,  5.5963e-03, -1.5089e+00,  1.8815e-01, -1.0905e+00,\n",
      "          -8.7135e-01, -7.3811e-04, -7.0268e-01],\n",
      "         [-6.0521e-01,  2.6147e-01,  4.1766e-01, -3.5814e-01,  3.4403e-01,\n",
      "          -2.9477e-01, -7.8140e-01,  1.0379e+00],\n",
      "         [-4.3601e-01,  8.8101e-01, -5.2223e-01,  7.6835e-01,  7.5641e-01,\n",
      "          -7.0552e-02, -9.1096e-01, -1.7755e+00],\n",
      "         [-2.1190e-01,  6.7628e-01, -9.9943e-01, -1.9734e-01,  1.9756e+00,\n",
      "           1.3190e+00, -4.8041e-02,  6.7685e-01],\n",
      "         [ 3.4251e-01, -1.4634e+00,  8.4958e-01,  8.8005e-01,  4.8116e-01,\n",
      "          -7.5287e-01, -2.2062e-01, -1.4990e-01],\n",
      "         [-2.3055e-01, -2.1300e+00, -5.1149e-01,  5.2352e-02,  1.1980e-01,\n",
      "          -8.4235e-02, -1.1027e+00, -1.0226e+00],\n",
      "         [-7.6862e-01, -8.6556e-01,  3.9920e-01, -6.7206e-01,  5.8915e-01,\n",
      "          -2.0144e+00, -1.4940e+00,  2.6160e-01],\n",
      "         [-7.2757e-01, -9.1791e-01, -2.1759e-01,  3.7383e-01,  9.9149e-01,\n",
      "          -1.4258e-01,  5.5486e-01,  3.0605e-01],\n",
      "         [ 3.1529e+00, -8.3162e-01, -7.5502e-01, -1.6312e+00,  5.9471e-01,\n",
      "          -4.6904e-02, -9.7440e-01, -6.0271e-02],\n",
      "         [-9.8379e-01,  1.2482e+00,  1.0808e+00,  2.0920e+00, -1.2660e-01,\n",
      "          -1.9995e-01,  5.4653e-01,  6.5345e-01]],\n",
      "\n",
      "        [[-9.1280e-01, -1.4383e+00, -1.8630e-02, -3.3205e-02, -1.2493e+00,\n",
      "          -1.5918e+00, -1.8351e-01, -1.4582e-01],\n",
      "         [-3.5824e-01,  6.6895e-01, -6.3131e-01, -1.8106e+00, -5.2038e-01,\n",
      "           5.0739e-01, -4.6385e-01, -1.0108e+00],\n",
      "         [ 1.2766e+00,  5.7632e-01,  1.5901e+00, -5.2731e-01, -6.7906e-01,\n",
      "           1.0092e+00, -1.0788e+00, -1.7313e-01],\n",
      "         [ 1.5054e+00, -9.0111e-01, -3.9865e-01,  6.5104e-01,  6.5172e-01,\n",
      "          -4.6742e-01,  1.2722e+00,  2.3617e+00],\n",
      "         [-1.9635e-01,  1.0219e-01,  7.8108e-01,  1.0462e+00,  1.2737e-01,\n",
      "          -1.6393e-01,  1.6889e+00, -9.9903e-01],\n",
      "         [-1.8126e+00, -1.2100e+00,  9.2383e-01, -9.8547e-01, -3.7221e-01,\n",
      "           2.2383e+00,  2.1299e-01, -1.9772e+00],\n",
      "         [-1.3112e-01, -3.7173e-01, -1.1642e-01,  1.8835e+00,  1.1602e+00,\n",
      "           2.3784e+00, -2.3231e+00,  1.9183e-01],\n",
      "         [ 8.1423e-01,  9.5626e-01,  6.8703e-01,  8.1120e-01,  5.6783e-01,\n",
      "           1.9072e+00,  6.1611e-02,  1.9759e+00],\n",
      "         [-9.0402e-01, -7.4581e-01,  1.2142e+00,  3.4883e-01,  8.9731e-01,\n",
      "           2.6662e-01,  3.0378e+00, -9.0088e-01],\n",
      "         [ 1.9833e-01, -1.1419e+00, -9.2215e-01,  7.3802e-01,  1.2698e-01,\n",
      "          -1.1037e+00,  2.2408e+00,  4.5673e-01]],\n",
      "\n",
      "        [[ 1.1272e+00,  2.1651e+00,  9.6375e-01,  4.8009e-01, -1.5805e+00,\n",
      "          -1.9103e-01, -2.8505e-01,  2.0058e+00],\n",
      "         [ 5.9136e-02, -1.1721e-01,  1.7387e-01, -5.3522e-01,  1.5019e+00,\n",
      "          -3.7081e-01,  1.1674e-01, -1.7828e-01],\n",
      "         [ 1.0167e+00, -1.7920e+00,  6.9834e-02,  3.9209e-01, -1.5275e-01,\n",
      "           7.9949e-01,  8.7193e-01, -6.5456e-01],\n",
      "         [-1.4459e+00,  2.5920e+00,  2.2279e+00,  1.5107e+00, -2.5601e+00,\n",
      "           1.7733e-01,  1.0110e+00,  1.1068e+00],\n",
      "         [ 2.0462e+00,  1.0119e+00,  5.8222e-01,  7.4706e-01, -1.1886e+00,\n",
      "          -1.6910e-01, -1.6733e+00,  7.5917e-01],\n",
      "         [ 4.1505e-01, -5.6643e-01,  1.9388e-02, -1.5035e+00,  2.5870e-01,\n",
      "           1.9635e-01,  5.4299e-01,  1.1865e-01],\n",
      "         [ 2.0841e-01,  9.9818e-01, -5.0757e-01, -1.1459e+00, -1.0413e-01,\n",
      "          -3.7494e-01, -1.6188e+00,  3.4163e-01],\n",
      "         [ 1.3167e+00,  1.4573e+00,  1.3568e-01, -3.6452e-01, -2.0994e-01,\n",
      "          -4.0895e-01,  5.6083e-01,  1.2476e+00],\n",
      "         [ 7.1812e-01,  1.6010e+00,  5.9838e-01,  3.5262e-02,  5.8537e-01,\n",
      "          -7.9764e-01,  6.5382e-01, -8.0316e-01],\n",
      "         [ 1.4728e-01, -2.7139e-01,  3.9853e-01,  1.4578e+00,  1.3563e+00,\n",
      "          -6.7295e-01, -8.1164e-01, -1.0022e-01]],\n",
      "\n",
      "        [[-7.0136e-03,  3.6673e-01,  1.6216e+00,  1.2775e+00, -6.6120e-01,\n",
      "           4.5526e-01,  7.9957e-01,  1.2997e+00],\n",
      "         [-3.2087e+00, -2.2009e+00,  2.0708e-01,  2.7124e+00,  5.9575e-01,\n",
      "          -2.3234e+00, -2.1467e+00, -4.3954e-01],\n",
      "         [-4.4959e-01,  2.3042e-01,  3.0467e+00, -1.2623e-01,  1.3151e+00,\n",
      "          -1.1191e+00,  1.7798e+00, -1.3477e+00],\n",
      "         [-9.4525e-01, -1.6177e-01, -5.3560e-01,  4.2685e-01, -1.3500e+00,\n",
      "          -6.0765e-01,  1.3178e+00,  1.6881e+00],\n",
      "         [-1.9797e-01, -1.0405e+00,  5.8328e-01,  2.3509e+00,  9.1034e-01,\n",
      "          -1.7356e+00, -3.2146e-01,  1.0873e+00],\n",
      "         [ 7.1395e-01,  1.4476e+00,  5.9732e-01, -1.3121e+00, -5.1366e-01,\n",
      "           2.0033e-01, -1.8753e-01,  9.0328e-01],\n",
      "         [ 8.6375e-03, -1.2784e+00,  2.4772e+00, -1.3852e-01,  1.3864e+00,\n",
      "           1.5310e-02, -3.3680e-01,  2.7511e-01],\n",
      "         [-6.5949e-02,  1.7377e+00,  5.1159e-01, -1.1127e-02, -6.6941e-01,\n",
      "          -2.5548e-01,  1.4419e+00, -8.2609e-01],\n",
      "         [-5.8749e-02,  1.7571e-01, -1.3551e+00, -1.1473e+00,  3.7752e-01,\n",
      "          -2.7355e-01,  1.6642e-02,  1.1582e+00],\n",
      "         [ 4.6994e-01, -8.4259e-01, -1.6538e+00,  5.8556e-01,  8.3412e-01,\n",
      "           7.7927e-01,  5.4197e-01,  2.1635e+00]]])\n",
      "torch.Size([4, 10, 8])\n"
     ]
    }
   ],
   "source": [
    "input1 = torch.randn(4,10,8)\n",
    "output1 = torch.chunk(input1, 11, dim=1)\n",
    "print(type(output1))\n",
    "for chunk in output1:\n",
    "    print(chunk.size())\n",
    "\n",
    "output2 = torch.split(input1, 11, dim=1)\n",
    "for chunk in output2:\n",
    "    print(chunk.size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "squeeze可以删除尺寸为1的维度。\n",
    "unsqueeze就是增加一维。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.9699, 0.3483, 0.6220],\n        [0.4750, 0.3475, 0.8540]])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(1,2,3)\n",
    "a.squeeze(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[0.4190, 0.6260, 0.0429],\n          [0.0024, 0.0396, 0.0181]]]])"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(1,2,3)\n",
    "a.unsqueeze(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "对张量使用cuda方法可以将张量从cpu搬到gpu。\n",
    "再次调用cpu可以搬回来。\n",
    "\n",
    "在那以前先确认是否可以使用gpu。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0.9699, 0.3483, 0.6220],\n         [0.4750, 0.3475, 0.8540]]], device='cuda:0')"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0.9699, 0.3483, 0.6220],\n         [0.4750, 0.3475, 0.8540]]])"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.cpu()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "torch.cuda.device_count() #返回gpu数量。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "'GeForce GTX 1660 Ti'"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0) #返回gpu名字,设备索引默认从0开始。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "运算速度对比："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2502.1125, 2492.1038, 2504.5610,  ..., 2474.5330, 2500.9622,\n         2491.8679],\n        [2505.2708, 2517.1235, 2485.7771,  ..., 2480.0925, 2502.1731,\n         2503.4441],\n        [2496.4150, 2527.9297, 2504.4768,  ..., 2503.2703, 2515.6689,\n         2505.7969],\n        ...,\n        [2530.3528, 2528.3135, 2516.9395,  ..., 2486.0198, 2502.7905,\n         2520.9678],\n        [2512.1865, 2517.8069, 2491.5547,  ..., 2494.9976, 2506.6116,\n         2518.1348],\n        [2502.6599, 2507.1782, 2494.0054,  ..., 2474.8340, 2505.6025,\n         2505.6494]])"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(10000,10000)\n",
    "b = torch.rand(10000,10000)\n",
    "\n",
    "a.matmul(b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2502.1055, 2492.1025, 2504.5554,  ..., 2474.5310, 2500.9602,\n         2491.8738],\n        [2505.2664, 2517.1260, 2485.7825,  ..., 2480.0928, 2502.1724,\n         2503.4448],\n        [2496.4104, 2527.9282, 2504.4783,  ..., 2503.2683, 2515.6721,\n         2505.7969],\n        ...,\n        [2530.3596, 2528.3137, 2516.9390,  ..., 2486.0212, 2502.7959,\n         2520.9714],\n        [2512.1887, 2517.7974, 2491.5576,  ..., 2494.9917, 2506.6116,\n         2518.1335],\n        [2502.6621, 2507.1868, 2494.0100,  ..., 2474.8340, 2505.6055,\n         2505.6458]], device='cuda:0')"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = a.cuda()\n",
    "b = b.cuda()\n",
    "\n",
    "a.matmul(b)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}