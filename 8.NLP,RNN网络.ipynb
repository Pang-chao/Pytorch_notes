{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "将文本转换为字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'h', 'e', 'r', 'e', ' ', 'a', 'r', 'e', ' ', 'm', 'o', 'm', 'e', 'n', 't', 's', ' ', 'i', 'n', ' ', 'l', 'i', 'f', 'e', ' ', 'w', 'h', 'e', 'n', ' ', 'y', 'o', 'u', ' ', 'm', 'i', 's', 's', ' ', 's', 'o', 'm', 'e', 'o', 'n', 'e', ' ', 's', 'o', ' ', 'm', 'u', 'c', 'h', ' ', 't', 'h', 'a', 't', ' ', 'y', 'o', 'u', ' ', 'j', 'u', 's', 't', ' ', 'w', 'a', 'n', 't', ' ', 't', 'o', ' ', 'p', 'i', 'c', 'k', ' ', 't', 'h', 'e', 'm', ' ', 'f', 'r', 'o', 'm', ' ', 'y', 'o', 'u', 'r', ' ', 'd', 'r', 'e', 'a', 'm', 's', ' ', 'a', 'n', 'd', ' ', 'h', 'u', 'g', ' ', 't', 'h', 'e', 'm', ' ', 'f', 'o', 'r', ' ', 'r', 'e', 'a', 'l', '!', ' ', 'D', 'r', 'e', 'a', 'm', ' ', 'w', 'h', 'a', 't', ' ', 'y', 'o', 'u', ' ', 'w', 'a', 'n', 't', ' ', 't', 'o', ' ', 'd', 'r', 'e', 'a', 'm', ';', 'g', 'o', ' ', 'w', 'h', 'e', 'r', 'e', ' ', 'y', 'o', 'u', ' ', 'w', 'a', 'n', 't', ' ', 't', 'o', ' ', 'g', 'o', ';', 'b', 'e', ' ', 'w', 'h', 'a', 't', ' ', 'y', 'o', 'u', ' ', 'w', 'a', 'n', 't', ' ', 't', 'o', ' ', 'b', 'e', ',', 'b', 'e', 'c', 'a', 'u', 's', 'e', ' ', 'y', 'o', 'u', ' ', 'h', 'a', 'v', 'e', ' ', 'o', 'n', 'l', 'y', ' ', 'o', 'n', 'e', ' ', 'l', 'i', 'f', 'e', ' ', 'a', 'n', 'd', ' ', 'o', 'n', 'e', ' ', 'c', 'h', 'a', 'n', 'c', 'e', ' ', 't', 'o', ' ', 'd', 'o', ' ', 'a', 'l', 'l', ' ', 't', 'h', 'e', ' ', 't', 'h', 'i', 'n', 'g', 's', ' ', 'y', 'o', 'u', ' ', 'w', 'a', 'n', 't', ' ', 't', 'o', ' ', 'd', 'o', '.']\n"
     ]
    }
   ],
   "source": [
    "from torchtext.legacy import data, datasets\n",
    "from torchtext.vocab import GloVe,FastText,CharNGram\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "thor_review = \"There are moments in life when you miss someone so much \" \\\n",
    "              \"that you just want to pick them from your dreams and hug \" \\\n",
    "              \"them for real! Dream what you want to dream;go where you \" \\\n",
    "              \"want to go;be what you want to be,because you have only one \" \\\n",
    "              \"life and one chance to do all the things you want to do.\"\n",
    "print(list(thor_review))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "将文本转换为词"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There', 'are', 'moments', 'in', 'life', 'when', 'you', 'miss', 'someone', 'so', 'much', 'that', 'you', 'just', 'want', 'to', 'pick', 'them', 'from', 'your', 'dreams', 'and', 'hug', 'them', 'for', 'real!', 'Dream', 'what', 'you', 'want', 'to', 'dream;go', 'where', 'you', 'want', 'to', 'go;be', 'what', 'you', 'want', 'to', 'be,because', 'you', 'have', 'only', 'one', 'life', 'and', 'one', 'chance', 'to', 'do', 'all', 'the', 'things', 'you', 'want', 'to', 'do.']\n"
     ]
    }
   ],
   "source": [
    "print(thor_review.split())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "n-gram表示法"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('There', 'are'), ('are', 'moments'), ('moments', 'in'), ('in', 'life'), ('life', 'when'), ('when', 'you'), ('you', 'miss'), ('miss', 'someone'), ('someone', 'so'), ('so', 'much'), ('much', 'that'), ('that', 'you'), ('you', 'just'), ('just', 'want'), ('want', 'to'), ('to', 'pick'), ('pick', 'them'), ('them', 'from'), ('from', 'your'), ('your', 'dreams'), ('dreams', 'and'), ('and', 'hug'), ('hug', 'them'), ('them', 'for'), ('for', 'real!'), ('real!', 'Dream'), ('Dream', 'what'), ('what', 'you'), ('you', 'want'), ('want', 'to'), ('to', 'dream;go'), ('dream;go', 'where'), ('where', 'you'), ('you', 'want'), ('want', 'to'), ('to', 'go;be'), ('go;be', 'what'), ('what', 'you'), ('you', 'want'), ('want', 'to'), ('to', 'be,because'), ('be,because', 'you'), ('you', 'have'), ('have', 'only'), ('only', 'one'), ('one', 'life'), ('life', 'and'), ('and', 'one'), ('one', 'chance'), ('chance', 'to'), ('to', 'do'), ('do', 'all'), ('all', 'the'), ('the', 'things'), ('things', 'you'), ('you', 'want'), ('want', 'to'), ('to', 'do.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "print(list(ngrams(thor_review.split(),2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "独热编码 one-hot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'There': 1, 'are': 2, 'moments': 3, 'in': 4, 'life': 5, 'when': 6, 'you': 7, 'miss': 8, 'someone': 9, 'so': 10, 'much': 11, 'that': 12, 'just': 13, 'want': 14, 'to': 15, 'pick': 16, 'them': 17, 'from': 18, 'your': 19, 'dreams': 20, 'and': 21, 'hug': 22, 'for': 23, 'real!': 24, 'Dream': 25, 'what': 26, 'dream;go': 27, 'where': 28, 'go;be': 29, 'be,because': 30, 'have': 31, 'only': 32, 'one': 33, 'chance': 34, 'do': 35, 'all': 36, 'the': 37, 'things': 38, 'do.': 39}\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Dictionary(object):\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = []\n",
    "        self.length = 0\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.idx2word:\n",
    "            self.idx2word.append(word)\n",
    "            self.word2idx[word] = self.length + 1\n",
    "            self.length += 1\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx2word)\n",
    "\n",
    "    def one_hot_encoded(self, word):\n",
    "        vec = np.zeros(self.length)\n",
    "        vec[self.word2idx[word]] = 1\n",
    "        return vec\n",
    "\n",
    "dic = Dictionary()\n",
    "\n",
    "for w in thor_review.split():\n",
    "    dic.add_word(w)\n",
    "\n",
    "print(dic.word2idx)\n",
    "dic.one_hot_encoded('what')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "下载IMDB数据并对文本分词\n",
    "（先安装torchtext）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "TEXT = data.Field(lower=True,fix_length=200,batch_first=False)\n",
    "LABEL = data.Field(sequential=False)\n",
    "train, test = datasets.IMDB.splits(TEXT, LABEL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "构建词表"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torchtext.legacy.data.iterator:The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "WARNING:torchtext.legacy.data.iterator:The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train, vectors=GloVe(name='6B', dim=300),max_size=10000,min_freq=10)\n",
    "LABEL.build_vocab(train)\n",
    "print(TEXT.vocab.freqs)\n",
    "train_iter, test_iter = data.BucketIterator.splits((train, test), batch_size=32, device=torch.device)\n",
    "train_iter.repeat = False\n",
    "test_iter.repeat = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "LSTM网络"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class IMDBRnn(nn.Module):\n",
    "\n",
    "    def __init__(self,vocab,hidden_size,n_cat,bs=1,nl=2):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bs = bs\n",
    "        self.nl = nl\n",
    "        self.e = nn.Embedding(n_vocab,hidden_size)\n",
    "        self.rnn = nn.LSTM(hidden_size,hidden_size,nl)\n",
    "        self.fc2 = nn.Linear(hidden_size,n_cat)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self,inp):\n",
    "        bs = inp.size()[1]\n",
    "        if bs != self.bs:\n",
    "            self.bs = bs\n",
    "        e_out = self.e(inp)\n",
    "        h0 = c0 = Variable(e_out.data.new(*(self.nl,self.bs,self.hidden_size)).zero_())\n",
    "        rnn_o,_ = self.rnn(e_out,(h0,c0))\n",
    "        rnn_o = rnn_o[-1]\n",
    "        fc = F.dropout(self.fc2(rnn_o),p=0.8)\n",
    "        return self.softmax(fc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "n_vocab = len(TEXT.vocab)\n",
    "n_hidden = 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "model = IMDBRnn(n_vocab,n_hidden,3,bs=32)\n",
    "model = model.cuda()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr=1e-3)\n",
    "\n",
    "def fit(epoch,model,data_loader,phase='training',volatile=False):\n",
    "    if phase == 'training':\n",
    "        model.train()\n",
    "    if phase == 'validation':\n",
    "        model.eval()\n",
    "        volatile=True\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    for batch_idx , batch in enumerate(data_loader):\n",
    "        text , target = batch.text , batch.label\n",
    "        if is_cuda:\n",
    "            text,target = text.cuda(),target.cuda()\n",
    "\n",
    "        if phase == 'training':\n",
    "            optimizer.zero_grad()\n",
    "        output = model(text)\n",
    "        loss = F.nll_loss(output,target)\n",
    "\n",
    "        running_loss += F.nll_loss(output,target,reduction='sum').item()\n",
    "        preds = output.data.max(dim=1,keepdim=True)[1]\n",
    "        running_correct += preds.eq(target.data.view_as(preds)).cpu().sum()\n",
    "        if phase == 'training':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    loss = running_loss/len(data_loader.dataset)\n",
    "    accuracy = 100. * running_correct/len(data_loader.dataset)\n",
    "\n",
    "    print(f'{phase} loss is {loss:{5}.{2}} and {phase} accuracy is {running_correct}/{len(data_loader.dataset)}{accuracy:{10}.{4}}')\n",
    "    return loss,accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pc/anaconda3/envs/mocnf/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is   1.0 and training accuracy is 6181/25000     24.72\n",
      "validation loss is   1.0 and validation accuracy is 6032/25000     24.13\n",
      "training loss is   1.0 and training accuracy is 6110/25000     24.44\n",
      "validation loss is   1.0 and validation accuracy is 6209/25000     24.84\n",
      "training loss is   1.0 and training accuracy is 6128/25000     24.51\n",
      "validation loss is   1.0 and validation accuracy is 6198/25000     24.79\n",
      "training loss is  0.99 and training accuracy is 6074/25000      24.3\n",
      "validation loss is  0.99 and validation accuracy is 5672/25000     22.69\n"
     ]
    }
   ],
   "source": [
    "train_losses , train_accuracy = [],[]\n",
    "val_losses , val_accuracy = [],[]\n",
    "\n",
    "for epoch in range(1,5):\n",
    "\n",
    "    epoch_loss, epoch_accuracy = fit(epoch,model,train_iter,phase='training')\n",
    "    val_epoch_loss , val_epoch_accuracy = fit(epoch,model,test_iter,phase='validation')\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracy.append(epoch_accuracy)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is  0.98 and training accuracy is 6115/25000     24.46\n",
      "validation loss is  0.99 and validation accuracy is 6277/25000     25.11\n",
      "training loss is  0.97 and training accuracy is 6003/25000     24.01\n",
      "validation loss is  0.99 and validation accuracy is 6168/25000     24.67\n",
      "training loss is  0.95 and training accuracy is 6173/25000     24.69\n",
      "validation loss is  0.95 and validation accuracy is 6071/25000     24.28\n",
      "training loss is  0.92 and training accuracy is 6414/25000     25.66\n",
      "validation loss is  0.93 and validation accuracy is 6265/25000     25.06\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}