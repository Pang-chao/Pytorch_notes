{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fizz Buzz游戏：\n",
    "\n",
    "给你一个整数n. 从 1 到 n 按照下面的规则打印每个数：\n",
    "如果这个数被3整除，打印fizz.\n",
    "如果这个数被5整除，打印buzz.\n",
    "如果这个数能同时被3和5整除，打印fizz buzz.\n",
    "\n",
    "先对输入数字进行二值编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def binary_encoder(input_size):\n",
    "    def wrapper(num):\n",
    "        ret = [int(i) for i in '{0:b}'.format(num)]\n",
    "        return [0] * (input_size - len(ret)) + ret\n",
    "    return wrapper\n",
    "\n",
    "def get_numpy_data(input_size, limit=1000):\n",
    "    x, y = [], []\n",
    "    encoder = binary_encoder(input_size)\n",
    "    for i in range(limit):\n",
    "        x.append(encoder(i))\n",
    "        if i % 15 == 0:\n",
    "            y.append([1,0,0,0])\n",
    "        elif i % 5 == 0:\n",
    "            y.append([0,1,0,0])\n",
    "        elif i % 3 == 0:\n",
    "            y.append([0,0,1,0])\n",
    "        else:\n",
    "            y.append([0,0,0,1])\n",
    "    return np.array(x), np.array(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "定义超参数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "batches = 64\n",
    "lr = 0.01\n",
    "input_size = 10\n",
    "output_size = 4\n",
    "hidden_size = 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "自动求导\n",
    "从get_numpy_data()创建Pytorch张量。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "trX, trY = get_numpy_data(input_size)\n",
    "x = torch.from_numpy(trX)\n",
    "y = torch.from_numpy(trY)\n",
    "w1 = torch.randn(input_size, hidden_size, requires_grad=True)\n",
    "w2 = torch.randn(hidden_size, output_size, requires_grad=True)\n",
    "b1 = torch.zeros(1, hidden_size, requires_grad=True)\n",
    "b2 = torch.zeros(1, output_size, requires_grad=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([2.])"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "inputs = torch.FloatTensor([2])\n",
    "weights = torch.rand(1, requires_grad=True)\n",
    "bias = torch.rand(1, requires_grad=True)\n",
    "t = inputs @ weights\n",
    "out = t + bias\n",
    "out.backward()\n",
    "weights.grad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1.])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias.grad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "张量实例中主要有三个属性用于支持自动求导：grad， .data, grad_fn().\n",
    ".grad属性存储任意节点在任意时间点的梯度。.data用于访问包含属性的裸张量对象。\n",
    "张量实例与Function实例在图上是相互连接的。除了用户明确定义的张量，\n",
    "每个张量都与一个函数相连。可以在张量上调用grade_fn来访问创建函数。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None <AddBackward0 object at 0x7f48c60490a0> tensor([[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  1.,  0.],\n",
      "        ...,\n",
      "        [ 2.,  0.,  0.,  ...,  0.,  1., -2.],\n",
      "        [ 2.,  0.,  0.,  ...,  0.,  2., -2.],\n",
      "        [ 2.,  0.,  0.,  ...,  0.,  2., -2.]], grad_fn=<AddBackward0>)\n",
      "torch.Size([64, 100])\n",
      "None None tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 1],\n",
      "        [0, 0, 0,  ..., 0, 1, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 0, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])\n",
      "None None tensor([[-4.8214e-01,  1.0064e+00, -9.6264e-01, -2.1357e+00,  5.0165e-01,\n",
      "          3.7822e+00, -1.1739e+00, -2.0010e-01,  1.1641e+00, -8.9520e-01,\n",
      "          1.1721e+00, -9.7261e-01,  1.7953e-02, -1.3551e+00, -1.3430e+00,\n",
      "          8.7970e-02, -1.2600e-01, -3.3888e-01, -1.3617e+00,  1.5023e+00,\n",
      "          2.1298e-01,  5.0209e-01, -2.4988e-01,  2.0210e+00, -5.1063e-01,\n",
      "          1.2927e+00, -2.7197e-02, -4.7923e-01, -1.4678e-01, -3.4817e-01,\n",
      "         -1.6054e+00,  3.4158e-01, -7.6343e-01, -7.9617e-01,  1.3228e+00,\n",
      "         -1.5158e-01, -2.2840e+00,  1.2099e+00,  6.1946e-01,  2.4562e-02,\n",
      "         -1.5655e+00, -7.8693e-01, -4.8811e-01, -4.7172e-02, -3.5601e-01,\n",
      "          8.9912e-01, -5.5707e-01, -1.8180e+00,  1.7017e+00, -1.5169e+00,\n",
      "         -1.1256e+00,  7.8084e-03, -9.9920e-02, -1.1447e-01, -2.4153e-01,\n",
      "         -1.0007e+00,  9.0499e-01, -5.9345e-01,  9.9558e-01,  3.3725e-01,\n",
      "         -2.1208e-01, -1.8878e+00,  6.4119e-01, -6.6210e-01,  1.5375e-02,\n",
      "         -1.0239e+00, -4.7526e-01,  2.1899e-01,  4.4546e-01, -1.3569e+00,\n",
      "         -5.6745e-01,  1.3891e+00,  3.1667e-01,  5.8487e-01,  1.4530e-01,\n",
      "          1.2675e-01,  1.3054e+00,  3.4209e-01, -8.7799e-01, -1.1710e+00,\n",
      "          6.5778e-02,  1.1008e+00, -3.7951e-01,  8.1691e-01,  7.2980e-01,\n",
      "         -3.5279e-01,  8.4358e-01, -3.6710e-01,  5.0357e-01, -6.4274e-01,\n",
      "         -1.0996e+00, -1.2390e+00,  1.8509e+00,  2.0097e+00, -2.3301e-01,\n",
      "          1.1142e+00,  7.4509e-02, -1.5802e-01,  8.1165e-01, -3.7488e-01],\n",
      "        [-4.2691e-01, -1.8575e+00, -1.2672e+00, -1.4112e+00, -3.3729e-01,\n",
      "         -1.2698e+00,  1.3223e+00, -7.9289e-01, -9.7936e-01, -3.0909e-01,\n",
      "         -5.5050e-01, -7.5646e-01, -1.7800e+00,  6.9117e-02, -9.3824e-01,\n",
      "          1.6034e+00,  2.5211e+00,  1.1722e+00, -4.7604e-01,  8.5610e-01,\n",
      "         -6.0191e-01, -1.4260e-01, -1.5441e+00, -1.4121e+00, -1.0606e+00,\n",
      "         -1.1071e+00,  1.1538e+00,  5.4928e-01,  8.2816e-02,  1.1275e+00,\n",
      "         -2.5393e-01, -6.4607e-02, -1.4096e-01, -2.3835e-01, -8.2943e-01,\n",
      "          9.6278e-01,  1.1463e+00, -6.0963e-01,  2.9494e-01,  7.2946e-01,\n",
      "          4.9352e-01, -5.8190e-01,  1.4448e+00, -1.1005e+00,  8.4951e-01,\n",
      "          2.5817e-01,  5.2269e-01, -1.3573e+00,  1.1047e+00, -5.6784e-01,\n",
      "          1.8123e-01, -4.6229e-01,  1.6961e+00,  7.2836e-01,  1.8336e-01,\n",
      "          1.1371e+00,  1.8870e+00, -1.4044e-01,  2.2486e+00,  5.1471e-01,\n",
      "         -1.9620e-01,  6.1147e-01,  3.6393e-01,  7.5162e-01,  1.5241e+00,\n",
      "          1.2716e-01,  1.2031e+00, -3.3095e-01,  1.3386e+00,  4.7964e-01,\n",
      "         -5.7444e-01, -8.5824e-01,  1.5469e-01,  4.3376e-02,  2.7084e-01,\n",
      "         -1.5539e+00, -2.1148e+00,  8.8560e-02, -1.5616e+00, -4.6016e-01,\n",
      "         -7.0200e-02, -1.5677e+00, -8.7740e-01,  6.2307e-01, -3.4960e-01,\n",
      "         -9.9750e-01, -3.8336e-01,  4.6620e-02, -5.1321e-01, -8.9739e-01,\n",
      "          1.5012e+00,  2.0743e+00, -1.0178e+00,  7.0068e-01, -1.2580e+00,\n",
      "          1.0469e+00, -1.0619e+00,  1.0857e-01,  1.6779e+00, -1.0318e+00],\n",
      "        [ 7.9182e-01,  1.6704e+00,  5.9465e-01,  8.6717e-01,  9.7779e-01,\n",
      "         -1.3014e+00, -1.4507e-01,  1.0352e-01,  1.5662e-01,  2.2112e-01,\n",
      "         -1.4847e+00,  1.9708e+00, -7.9733e-01,  5.1375e-01,  9.9060e-02,\n",
      "          1.3659e-01,  8.5309e-01,  1.7842e+00, -8.3956e-02, -7.7190e-01,\n",
      "         -2.7710e-01,  4.1227e-01,  7.7012e-01, -5.3941e-01, -9.7583e-01,\n",
      "         -2.6746e-01,  5.8782e-01,  1.3609e-01,  1.6166e+00, -1.2620e+00,\n",
      "          1.8588e+00, -1.6112e-02,  4.1567e-01, -2.1722e+00,  4.2794e-01,\n",
      "         -7.0588e-02,  7.1336e-01,  1.8235e+00, -1.6276e-01, -1.1383e-01,\n",
      "         -4.7917e-02,  7.5131e-01, -4.0840e-01, -8.8917e-01, -2.2828e+00,\n",
      "          1.0271e+00, -1.2522e-01,  1.5598e-01,  1.1442e+00, -3.0233e-01,\n",
      "         -3.0178e-01, -1.3943e+00, -1.0430e+00, -1.1642e+00, -3.1170e-01,\n",
      "         -4.1338e-02,  4.8432e-01, -6.7347e-01, -1.4243e+00,  5.3094e-01,\n",
      "         -1.3186e+00,  5.0917e-01,  5.4082e-01,  2.7706e-01,  7.4129e-01,\n",
      "          2.6428e-02, -4.8151e-01,  1.6226e-01, -2.8694e+00, -2.3886e-01,\n",
      "         -9.1642e-01, -5.2649e-01, -1.1120e+00,  4.2483e-01, -1.4360e+00,\n",
      "         -2.4072e-01, -6.6188e-01,  1.6183e+00,  2.9419e-01,  5.9180e-02,\n",
      "         -1.2493e+00,  9.4980e-01, -1.0181e+00,  1.6383e+00,  8.0510e-02,\n",
      "         -1.1331e-01, -7.0655e-01,  7.7936e-01, -6.2809e-01, -2.1805e-01,\n",
      "         -6.0850e-01, -4.5058e-01, -4.0336e-01,  2.2256e-01, -6.0491e-01,\n",
      "         -9.4632e-01, -5.4284e-01, -1.0962e+00,  5.9551e-01, -1.2842e-01],\n",
      "        [-5.6298e-01,  1.2755e+00,  1.0676e+00,  9.5953e-01, -5.6906e-01,\n",
      "          1.0040e-01,  1.1849e+00, -8.8530e-01, -9.2883e-01, -2.8017e-02,\n",
      "         -8.5170e-01,  1.4166e+00,  1.3833e+00, -6.2010e-01,  1.1850e-01,\n",
      "         -1.2270e+00, -1.9754e+00, -1.0387e+00, -5.1968e-01,  8.7508e-01,\n",
      "          1.3430e-02,  4.7561e-01, -8.9410e-01, -2.1479e+00,  1.7990e-01,\n",
      "         -5.5187e-01,  2.2808e-01, -2.1885e+00, -7.4715e-02,  1.3253e+00,\n",
      "         -1.2066e+00,  9.2479e-01, -5.3947e-02, -1.1241e-01,  1.0127e+00,\n",
      "         -9.7480e-01, -7.6209e-02, -3.0518e-01, -5.4191e-01,  3.6102e-01,\n",
      "         -7.1680e-02, -5.8727e-01,  7.2030e-01, -1.8451e+00,  5.0137e-01,\n",
      "          6.1723e-01, -4.0359e-02, -1.0163e+00,  3.6062e-01, -4.4498e-01,\n",
      "         -5.6334e-01, -4.9591e-01, -5.4147e-01, -1.3164e+00, -8.3000e-01,\n",
      "         -9.9418e-01,  5.5544e-01,  3.3290e-01,  6.1621e-01,  1.3176e+00,\n",
      "         -2.3173e-02, -7.2128e-01,  1.0675e+00, -3.8345e-01, -1.6472e+00,\n",
      "         -9.0471e-02, -7.0203e-01, -1.8245e+00,  6.6128e-01, -2.0525e-02,\n",
      "         -1.4374e-01, -3.4274e-01,  2.9595e+00,  6.3305e-02,  1.0506e+00,\n",
      "          2.2192e+00, -4.2171e-01,  1.2403e+00, -9.6474e-01,  7.8565e-01,\n",
      "          5.8457e-01,  1.1182e+00, -1.4829e-01,  9.4093e-01, -7.3656e-01,\n",
      "          8.4689e-01,  9.4940e-01,  7.0083e-01, -1.5928e+00,  1.2050e-01,\n",
      "         -1.0555e+00,  2.0121e-02,  1.4717e+00, -2.1450e+00,  1.0049e+00,\n",
      "          1.3128e+00, -3.0765e+00, -9.7194e-01,  5.5331e-01, -2.0611e+00],\n",
      "        [ 1.1687e+00, -5.9558e-01, -1.3040e+00,  1.8128e+00, -1.5180e-01,\n",
      "         -2.1472e-01,  4.3101e-01,  1.6722e-02, -1.3749e+00,  1.3553e+00,\n",
      "          4.2862e-01,  5.5891e-01,  6.6707e-01,  9.3740e-01, -1.1775e+00,\n",
      "          7.9405e-01, -1.3058e+00,  7.4252e-01, -1.3606e+00,  6.1801e-01,\n",
      "         -8.2798e-01, -3.9722e-01,  2.3153e-01, -1.7031e+00, -3.3993e-01,\n",
      "          1.0057e+00,  1.2139e+00, -2.0026e-01, -3.2541e-01, -3.8725e-02,\n",
      "          7.5410e-01,  6.7885e-01,  1.0318e+00, -1.5674e+00, -8.9924e-01,\n",
      "          1.3934e-01, -2.1132e+00,  3.6246e-01, -3.7194e-01, -1.2409e-01,\n",
      "          1.4027e+00,  1.0427e+00, -7.6224e-01,  1.2284e+00,  3.7768e-01,\n",
      "         -1.0015e+00,  7.4707e-01,  7.5764e-01,  1.9085e+00,  4.0312e-01,\n",
      "          5.9768e-02, -1.7093e-01, -6.8889e-02,  1.2062e-01,  2.0615e+00,\n",
      "         -1.1549e+00, -1.4910e+00, -5.4555e-01,  6.2638e-01, -2.1566e-01,\n",
      "         -3.0598e-01, -1.1215e+00,  8.2740e-02,  1.1017e-01, -9.9419e-01,\n",
      "         -2.8694e-01,  8.7216e-01, -3.1234e-01, -1.6944e+00,  2.9450e+00,\n",
      "          6.4755e-01,  3.5413e-01, -7.9723e-01, -1.2838e+00, -2.9443e-03,\n",
      "         -5.5796e-01, -1.2062e+00,  3.9785e-01, -5.2193e-01,  1.0975e+00,\n",
      "          2.7380e-01, -1.4413e+00,  6.3370e-01,  2.8154e-01, -2.8534e-01,\n",
      "         -1.6415e+00, -2.1381e+00,  3.3738e-01, -2.5112e-01,  1.6439e-01,\n",
      "         -1.1969e-01, -8.8880e-01,  1.5235e+00, -7.8329e-01,  1.8788e+00,\n",
      "         -4.1453e-02,  5.3581e-01,  2.1749e-01, -4.9308e-01,  1.9479e-01],\n",
      "        [ 7.0128e-01,  8.6869e-03,  1.2041e+00,  4.8660e-01, -4.3210e-01,\n",
      "          9.5229e-01,  1.5392e-01,  1.1136e+00, -1.5980e-02, -1.0728e-01,\n",
      "         -2.0477e-01,  2.0712e-01, -1.3887e+00,  9.4119e-02, -2.7187e-01,\n",
      "          3.8331e-02,  1.9907e-01,  3.1900e+00, -5.7831e-01, -1.1479e+00,\n",
      "          2.2290e+00, -6.9956e-02,  4.1211e-01,  1.9200e+00,  6.2364e-01,\n",
      "          1.1057e+00, -1.3416e-02, -7.6651e-01,  6.3995e-01,  4.4646e-01,\n",
      "         -3.3917e-01, -4.5435e-01,  2.5365e-01, -6.2681e-01,  1.2719e+00,\n",
      "          7.3897e-01, -1.4093e-01,  3.6041e-02,  1.7988e+00, -2.3017e+00,\n",
      "         -1.1689e-01, -1.0706e-01,  3.9968e-02, -3.1467e-01, -1.2018e-01,\n",
      "          1.2218e+00, -9.5195e-02,  5.5534e-02,  3.6571e-01,  5.6803e-01,\n",
      "         -2.2350e+00,  8.0140e-01, -2.7297e-01,  1.4228e+00,  1.1976e+00,\n",
      "         -1.6660e+00,  5.4998e-01, -9.6115e-02,  5.7283e-01, -3.7349e-02,\n",
      "          1.3221e+00,  4.0043e-01,  5.1354e-01, -1.6269e-01, -6.8452e-01,\n",
      "         -1.3807e+00,  7.5654e-01, -1.0511e+00,  4.8226e-01,  1.2975e+00,\n",
      "          1.1882e+00,  6.8571e-02, -1.8055e+00,  3.8209e-01,  1.0396e+00,\n",
      "         -2.0633e-01,  1.5735e+00, -6.0288e-02,  1.6155e+00,  9.0381e-01,\n",
      "         -1.5757e+00,  6.4098e-01, -4.3334e-01, -3.1989e-01,  7.5584e-01,\n",
      "         -4.6448e-01,  4.8882e-01, -1.6544e+00, -7.5810e-01, -9.0224e-01,\n",
      "          1.3839e+00, -1.9031e+00,  2.5497e-02, -1.5560e-01, -1.1317e+00,\n",
      "          2.1837e-01, -8.2736e-01, -3.0314e-01,  6.5894e-01,  7.3940e-01],\n",
      "        [ 2.0069e+00, -5.7674e-02,  1.6640e+00,  7.8301e-01, -6.9440e-01,\n",
      "          2.9215e-01, -9.5871e-01,  8.3525e-01, -5.2829e-03,  1.3324e-01,\n",
      "         -8.3009e-01,  1.5372e+00,  7.0066e-01, -4.3359e-02, -5.6635e-01,\n",
      "          1.4546e+00,  1.1386e+00, -5.5950e-01, -1.1024e+00, -1.4386e+00,\n",
      "          5.3202e-01,  4.7662e-01,  1.8869e-01, -1.0924e+00,  1.2469e+00,\n",
      "          2.2908e-01,  7.1776e-01,  3.0653e-01, -5.8523e-01,  2.7842e-01,\n",
      "          7.7067e-01, -6.6939e-02,  6.0401e-01, -2.0193e+00,  1.5897e+00,\n",
      "          3.2268e-01,  4.1374e-01,  1.4261e+00,  4.6696e-01,  3.9250e-01,\n",
      "          6.8268e-01, -3.3361e-01,  1.3684e+00,  6.0535e-01,  5.9453e-01,\n",
      "          7.9593e-01, -4.6755e-01,  1.0361e-01, -8.6993e-02, -3.4825e-01,\n",
      "          4.8218e-01,  5.5041e-01,  9.6150e-01,  1.0709e+00,  8.4259e-01,\n",
      "         -2.4707e+00,  8.0420e-01,  4.1397e-01, -4.8567e-01, -4.6239e-01,\n",
      "          1.1454e-01, -1.4078e+00,  4.0154e-01, -1.8739e-01,  6.9949e-01,\n",
      "         -2.2735e-01, -1.5184e+00, -7.5082e-01, -1.1761e+00, -6.8240e-01,\n",
      "         -4.6222e-01, -1.4850e+00, -1.1235e+00, -4.5442e-01, -6.1117e-01,\n",
      "          7.7425e-01,  2.6086e-01,  1.5171e+00,  7.9327e-01, -1.7819e+00,\n",
      "          9.6362e-01,  1.0351e+00, -2.0726e-01,  5.5748e-01, -3.6378e-01,\n",
      "         -1.7514e+00, -1.1510e+00, -4.1177e-01,  6.8232e-01,  1.4256e+00,\n",
      "         -2.1176e+00,  1.2637e+00,  1.1298e+00,  1.7950e+00,  1.0732e+00,\n",
      "         -2.4258e-01,  9.3661e-01, -2.2724e-01,  1.0420e+00, -1.6674e+00],\n",
      "        [-1.1426e+00,  8.6749e-01, -1.6157e+00, -3.8229e-01,  1.3750e+00,\n",
      "         -6.9831e-01,  2.0214e+00,  3.7068e-01, -1.1016e-01,  1.6719e+00,\n",
      "          5.1931e-01, -2.7743e-01, -9.0605e-01,  5.9288e-01,  7.3918e-01,\n",
      "         -1.9341e-01, -1.1143e+00, -7.3079e-01,  1.2059e+00, -1.8299e+00,\n",
      "          1.5874e-01,  7.4217e-01, -7.0821e-03, -4.5461e-01,  2.0352e-01,\n",
      "         -1.2463e+00, -1.2818e+00,  1.6900e-01, -9.5062e-01,  6.2815e-01,\n",
      "          2.2822e-01,  7.7766e-01, -1.5113e+00, -8.1531e-01, -7.0057e-01,\n",
      "         -8.5867e-01,  1.2904e+00,  4.0210e-01, -2.8761e-01,  3.4100e-01,\n",
      "         -1.4296e+00, -3.4770e-01, -3.2202e-01,  1.1117e-02,  1.4690e+00,\n",
      "         -7.1354e-01, -2.5298e-01, -7.2243e-01, -8.4267e-01,  1.3638e+00,\n",
      "          5.3770e-01,  2.1986e+00, -2.4917e-01,  1.7911e+00, -3.4000e-01,\n",
      "          3.1579e-01,  6.6339e-01,  9.8821e-02, -8.3219e-01, -1.7294e+00,\n",
      "         -2.8744e-01, -7.2869e-02,  5.7821e-01,  6.7011e-01,  1.3443e-01,\n",
      "          3.8741e-02, -1.4793e+00, -3.9558e-01,  2.6448e-01,  4.2033e-01,\n",
      "          1.6188e+00, -1.2068e+00,  9.7623e-01, -1.2912e+00,  3.7296e-02,\n",
      "          1.5578e+00, -7.7931e-01,  2.0503e+00,  6.6593e-01,  5.8845e-01,\n",
      "          7.5564e-01, -2.7758e-01,  7.2229e-01, -7.0645e-01, -5.9191e-01,\n",
      "         -7.9627e-01, -1.0226e+00, -4.5204e-01,  2.4982e-01, -1.0558e-01,\n",
      "         -1.4208e-01,  1.3150e+00, -4.7601e-01,  1.5271e+00, -1.9620e+00,\n",
      "         -1.3472e-01, -4.1481e-01, -4.1445e-01, -8.8348e-01, -1.2205e+00],\n",
      "        [ 9.1813e-01,  7.6995e-01,  3.8530e-01,  7.6717e-01, -5.1882e-01,\n",
      "         -3.1249e-01,  1.1934e-01, -1.1977e+00, -7.2364e-01, -1.3928e+00,\n",
      "         -1.0789e+00,  6.5648e-01, -5.1691e-01, -8.4030e-01,  4.3841e-02,\n",
      "          2.3723e-02, -1.1014e+00, -2.3234e+00, -5.3174e-01,  1.0723e+00,\n",
      "         -8.6864e-01,  1.0810e+00, -8.5592e-01,  2.1850e+00, -6.6057e-01,\n",
      "          9.3276e-01, -2.9966e-01, -1.3980e-01, -8.0579e-02, -2.0056e+00,\n",
      "          7.0129e-01, -8.9545e-01,  1.2043e+00, -6.1281e-01, -3.2149e-01,\n",
      "          7.1757e-01,  6.5547e-01, -1.9946e-01,  2.1029e-01,  2.1210e+00,\n",
      "          5.3785e-01,  6.7077e-01, -1.5114e+00,  7.2672e-01, -9.0163e-01,\n",
      "         -1.5036e+00, -1.7183e+00,  6.7458e-01,  2.7435e-01,  6.8465e-01,\n",
      "          1.2322e+00, -3.3794e-01,  2.5968e-01, -1.4248e+00, -1.5420e+00,\n",
      "          7.1161e-01,  3.8535e-01,  2.0319e-01,  3.5978e-01, -1.8037e-01,\n",
      "          2.0298e-01, -2.1056e+00,  9.5658e-01, -1.4811e-01,  8.2879e-01,\n",
      "          1.4059e+00,  1.0144e+00, -6.1311e-01, -1.0488e-01, -9.3093e-02,\n",
      "         -3.1363e-01,  4.9714e-01,  1.4091e-01, -8.0752e-02,  1.3939e+00,\n",
      "          4.5136e-01,  8.6559e-01,  1.6026e+00, -9.3929e-01, -2.6051e-01,\n",
      "          1.4140e+00, -2.1767e+00, -1.1595e+00, -7.0510e-02, -1.1882e+00,\n",
      "         -7.7539e-01, -5.6602e-01,  2.2591e-01, -8.7413e-01,  8.9389e-01,\n",
      "          1.6245e+00,  6.5797e-01,  7.1865e-01, -6.3631e-01, -3.5718e-01,\n",
      "          3.9509e-01,  3.6333e-01, -2.1702e-01,  1.2247e+00, -2.7749e-01],\n",
      "        [ 3.4428e-01,  6.5595e-01,  5.3434e-01, -8.8517e-02, -1.6437e+00,\n",
      "         -1.2452e+00, -1.9025e-01, -7.8638e-01, -1.4717e+00, -7.0192e-01,\n",
      "         -1.7130e+00, -3.0740e-01, -5.4549e-01,  9.5240e-01,  5.0936e-01,\n",
      "         -1.6019e-01, -2.4069e-01,  9.8871e-01, -2.7150e+00, -8.7206e-01,\n",
      "          1.0792e-01, -1.0535e-01,  6.3245e-01,  8.9643e-01, -9.5410e-01,\n",
      "          7.9227e-01, -1.6878e+00, -6.6034e-01,  4.9665e-01, -1.4948e+00,\n",
      "          2.3487e-01, -1.4582e+00, -7.7259e-01, -1.2504e+00, -1.6393e+00,\n",
      "         -8.1818e-01,  1.8857e+00,  1.2536e-01,  9.5180e-01, -1.4620e+00,\n",
      "          9.1201e-01,  3.1364e+00, -1.0715e+00,  5.6726e-01, -1.1397e+00,\n",
      "          1.3719e-01, -7.4593e-01, -3.5407e-01, -1.6564e+00, -6.9321e-01,\n",
      "         -2.0210e+00, -4.5499e-01,  1.8159e+00,  9.4003e-01,  4.7180e-01,\n",
      "          8.9112e-01, -1.0176e+00, -5.6839e-01,  7.3039e-02, -3.8688e-01,\n",
      "          1.2334e+00, -1.2447e+00,  1.1245e+00, -1.6722e+00, -3.2634e-01,\n",
      "          3.3066e-01,  1.8329e+00, -7.8154e-01, -1.0241e+00, -1.7422e+00,\n",
      "         -5.9222e-01,  2.4101e+00, -1.0874e+00,  5.1799e-01,  8.8090e-01,\n",
      "         -7.8724e-01, -3.1429e-02, -1.2832e+00, -7.8873e-02, -1.0615e-01,\n",
      "         -4.7950e-01,  3.0991e-02,  5.2636e-01, -1.7903e+00,  1.6264e+00,\n",
      "          7.7973e-01,  1.1236e-01,  2.4744e+00,  3.5436e-01, -4.1153e-01,\n",
      "         -1.2754e-01, -1.4093e+00,  7.8673e-01, -7.6719e-01, -3.8887e-01,\n",
      "          1.9343e-01,  2.4687e+00, -5.2423e-01,  7.3426e-01, -9.2675e-01]],\n",
      "       requires_grad=True)\n",
      "None <AddBackward0 object at 0x7f48c603be50> tensor([[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  1.,  0.],\n",
      "        ...,\n",
      "        [ 2.,  0.,  0.,  ...,  0.,  1., -2.],\n",
      "        [ 2.,  0.,  0.,  ...,  0.,  2., -2.],\n",
      "        [ 2.,  0.,  0.,  ...,  0.,  2., -2.]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72953/2006177540.py:10: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information.\n",
      "  print(a2.grad, a2.grad_fn, a2)\n",
      "/tmp/ipykernel_72953/2006177540.py:30: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information.\n",
      "  print(a2.grad, a2.grad_fn, a2)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_72953/2006177540.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     32\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 33\u001B[0;31m             \u001B[0mw1\u001B[0m \u001B[0;34m-=\u001B[0m \u001B[0mlr\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mw1\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgrad\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     34\u001B[0m             \u001B[0mw2\u001B[0m \u001B[0;34m-=\u001B[0m \u001B[0mlr\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mw2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgrad\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     35\u001B[0m             \u001B[0mb1\u001B[0m \u001B[0;34m-=\u001B[0m \u001B[0mlr\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mb1\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgrad\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: unsupported operand type(s) for *: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch in range(10):\n",
    "        start = batch * batches\n",
    "        end = start + batches\n",
    "        x_ = x[start:end]\n",
    "        y_ = y[start:end]\n",
    "\n",
    "        a2 = x_.matmul(w1.long())\n",
    "        a2 = a2.add(b1)\n",
    "        print(a2.grad, a2.grad_fn, a2)\n",
    "        print(a2.size())\n",
    "\n",
    "        h2 = a2.sigmoid()\n",
    "        a3 = h2.matmul(w2)\n",
    "        a3 = a3.add(b2)\n",
    "        hyp = a3.sigmoid()\n",
    "        error = hyp - y_\n",
    "        #MSE,均方误差\n",
    "        output = error.pow(2).sum() / 2.0\n",
    "\n",
    "        '''w1.grad.zero_()\n",
    "        w2.grad.zero_()\n",
    "        b1.grad.zero_()\n",
    "        b2.grad.zero_()'''\n",
    "        #触发反向传播，并基于梯度更新\n",
    "        output.backward()\n",
    "\n",
    "        print(x.grad, x.grad_fn, x)\n",
    "        print(w1.grad, w1.grad_fn, w1)\n",
    "        print(a2.grad, a2.grad_fn, a2)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            w1 -= lr * w1.grad\n",
    "            w2 -= lr * w2.grad\n",
    "            b1 -= lr * b1.grad\n",
    "            b2 -= b2 * w1.grad\n",
    "\n",
    "        print(a2.grad, a2.grad_fn, a2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}